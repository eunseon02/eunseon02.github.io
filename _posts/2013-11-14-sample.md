---
layout: post
title: "SLIM: Self-Supervised LiDAR Scene Flow and Motion Segmentation"
categories: [paper review]
tags: [SLIM, scene representation]
description: Sample placeholder post.
---

이 논문은 simultaneous motion segmentation & scene flow estimation using self-supervised training를 위한 논문이다.
### Abstract
**scene flow estimation**을 위한 논문
이전의 연구들은 두 유형의 움직임-독립적으로 움직이는 agents & 센서의 움직임과 일관된 배경의 움직임  -을 self-supervised training 상에서 충분히 고려하지 못했다.

![Untitled](https://github.com/eunseon02/eunseon02.github.io/assets/108911413/78d4793a-83d8-4747-826d-225a3710aad5)


### Introduction
dynamic object의 motion 추정

simultaneous LiDAR scene flow estimation and motion segmentation using a
deep network

- motion segmentation : classification of point into either moving or stationary
- scene flow

### Related Work
**Self-Supervised Learning**

geometric, temporal/cyclic consistency losses 사용

→ predict optical flow, stereo flow, depth,  motion segmentation


### Method
![Untitled (1)](https://github.com/eunseon02/eunseon02.github.io/assets/108911413/9dca53f8-1918-4718-921a-af2d212fbbcb)

### Network Architecture
**Point Cloud Encoder:**
Pillar Feature Net (PFN)을 이용하여 포인트 클라우드를 다음과 같이 Pseudo image형태로 변환하였다.


${P}_t, {P}_{t+1}\in \mathbb{R}^{N \times 3}$ → $\mathcal{I}_t, \mathcal{I}_{t+1}\in \mathbb{R}^{H \times W \times C}$
$$\mathcal{P}_t, \mathcal{P}_{t+1}\in \mathbb{R}^{N \times 3}$$ → $$\mathcal{I}_t, \mathcal{I}_{t+1}\in \mathbb{R}^{H \times W \times C}$$
$$\textbf{P)_t$$
